"""
================================================================================
data_cleaner.py - M√≥dulo de Limpieza y Validaci√≥n de Datos
================================================================================
Responsabilidades:
- Filtrado de magic numbers (precios inv√°lidos del vendor)
- Validaci√≥n de precios y cantidades
- Detecci√≥n de crossed books (bid >= ask)
- Filtrado por market status (solo continuous trading)

Pipeline de limpieza (FASE 2):
1. Clean magic numbers
2. Clean invalid prices
3. Clean crossed books
4. Filter by market status
================================================================================
"""

import pandas as pd
import logging
from typing import Dict

from config_module import config

logger = logging.getLogger(__name__)


class DataCleaner:
    """
    Clase responsable de aplicar filtros de calidad de datos.
    
    CR√çTICO: La limpieza es esencial para evitar se√±ales de arbitraje falsas.
    Los magic numbers y estados de mercado inv√°lidos generar√≠an oportunidades
    que en realidad no son ejecutables.
    """
    
    @staticmethod
    def clean_magic_numbers(df: pd.DataFrame) -> pd.DataFrame:
        """
        Elimina snapshots con magic numbers en precios.
        
        CR√çTICO: Los magic numbers NO son precios reales. Son c√≥digos especiales
        del vendor para indicar estados como "Market Order", "Pegged Order", etc.
        
        Si no se filtran, se detectar√≠an oportunidades falsas con profits de
        millones de euros.
        
        Fuente: Arbitrage study in BME.docx - Section 2.A "Magic Numbers"
        
        Args:
            df: DataFrame con columnas px_bid_0 y px_ask_0
            
        Returns:
            DataFrame filtrado (sin magic numbers)
        """
        initial_len = len(df)
        
        # Crear m√°scaras: True si NO es magic number
        bid_mask = ~df['px_bid_0'].isin(config.MAGIC_NUMBERS)
        ask_mask = ~df['px_ask_0'].isin(config.MAGIC_NUMBERS)
        
        # Aplicar filtro combinado
        df_clean = df[bid_mask & ask_mask].copy()
        
        removed = initial_len - len(df_clean)
        if removed > 0:
            pct = removed / initial_len * 100
            logger.info(f"    Removed {removed:,} magic numbers ({pct:.2f}%)")
        
        return df_clean
    
    @staticmethod
    def clean_invalid_prices(df: pd.DataFrame) -> pd.DataFrame:
        """
        Valida que todos los precios y cantidades sean positivos y no-NaN.
        
        Validaciones:
        - px_bid_0 > 0
        - px_ask_0 > 0
        - qty_bid_0 > 0
        - qty_ask_0 > 0
        - No NaN values
        
        Args:
            df: DataFrame con columnas de precios y cantidades
            
        Returns:
            DataFrame con precios v√°lidos
        """
        initial_len = len(df)
        
        # M√°scara combinada de validaciones
        mask = (
            (df['px_bid_0'] > 0) &
            (df['px_ask_0'] > 0) &
            (df['qty_bid_0'] > 0) &
            (df['qty_ask_0'] > 0) &
            (df['px_bid_0'].notna()) &
            (df['px_ask_0'].notna())
        )
        
        df_clean = df[mask].copy()
        
        removed = initial_len - len(df_clean)
        if removed > 0:
            logger.info(f"    Removed {removed:,} invalid prices")
        
        return df_clean
    
    @staticmethod
    def clean_crossed_book(df: pd.DataFrame) -> pd.DataFrame:
        """
        Elimina snapshots donde bid >= ask dentro del mismo venue.
        
        Un "crossed book" indica error en los datos. En un mercado normal,
        el mejor bid siempre debe ser menor que el mejor ask dentro del
        mismo venue. Si bid >= ask, habr√≠a arbitraje instant√°neo y el
        mercado se auto-corregir√≠a inmediatamente.
        
        NOTA: Cross-venue arbitrage (bid de venue A > ask de venue B) es
        lo que QUEREMOS detectar. Esto solo filtra anomal√≠as internas.
        
        Args:
            df: DataFrame con px_bid_0 y px_ask_0
            
        Returns:
            DataFrame sin crossed books
        """
        initial_len = len(df)
        
        # Condici√≥n normal: bid < ask
        mask = df['px_bid_0'] < df['px_ask_0']
        df_clean = df[mask].copy()
        
        removed = initial_len - len(df_clean)
        if removed > 0:
            logger.warning(f"    Removed {removed:,} crossed books (bid >= ask)")
        
        return df_clean
    
    @staticmethod
    def filter_by_market_status(qte_df: pd.DataFrame, 
                                sts_df: pd.DataFrame, 
                                mic: str) -> pd.DataFrame:
        """
        Filtra snapshots para mantener SOLO los que ocurren durante
        continuous trading.
        
        CR√çTICO: Operar durante auctions, halts o pre-open generar√≠a se√±ales
        falsas. Las √≥rdenes no se ejecutar√≠an instant√°neamente en esos estados.
        
        M√©todo:
        - Usa pd.merge_asof con direction='backward' para propagar el √∫ltimo
          estado conocido hacia adelante
        - Filtra por c√≥digos de continuous trading seg√∫n venue
        
        Fuente: Arbitrage study in BME.docx - Section 2.B "Market Status Codes"
        
        Args:
            qte_df: DataFrame con quotes
            sts_df: DataFrame con trading status
            mic: Market Identifier Code (XMAD, AQXE, CEUX, TRQX)
            
        Returns:
            DataFrame filtrado (solo continuous trading)
        """
        # Validar datos de entrada
        if sts_df is None or len(sts_df) == 0:
            logger.warning(f"    No STS data for {mic}, skipping status filter")
            return qte_df
        
        if mic not in config.VALID_STATES:
            logger.warning(f"    Unknown MIC {mic}, skipping status filter")
            return qte_df
        
        initial_len = len(qte_df)
        
        # Ordenar ambos DataFrames por timestamp
        qte_sorted = qte_df.sort_values('epoch').copy()
        sts_sorted = sts_df[['epoch', 'market_trading_status']].sort_values('epoch').copy()
        
        # Merge asof: Asigna a cada snapshot el estado m√°s reciente anterior
        # direction='backward' significa "usar el √∫ltimo valor conocido"
        merged = pd.merge_asof(
            qte_sorted,
            sts_sorted,
            on='epoch',
            direction='backward'
        )
        
        # Filtrar por c√≥digos v√°lidos de continuous trading
        valid_codes = config.VALID_STATES[mic]
        merged_filtered = merged[
            merged['market_trading_status'].isin(valid_codes)
        ].copy()
        
        # Limpiar columna temporal
        if 'market_trading_status' in merged_filtered.columns:
            merged_filtered = merged_filtered.drop('market_trading_status', axis=1)
        
        removed = initial_len - len(merged_filtered)
        if removed > 0:
            pct = removed / initial_len * 100
            logger.info(f"    Removed {removed:,} non-trading snapshots ({pct:.2f}%)")
        
        return merged_filtered
    
    def clean_venue_data(self, venue_dict: Dict, mic: str) -> pd.DataFrame:
        """
        Aplica el pipeline completo de limpieza a un venue.
        
        Pipeline secuencial:
        1. Magic numbers
        2. Invalid prices
        3. Crossed books
        4. Market status
        
        Args:
            venue_dict: Dict con keys 'qte' y 'sts'
            mic: Market Identifier Code
            
        Returns:
            DataFrame limpio y validado
        """
        print(f"\n  üßπ Limpiando {mic}...")
        
        qte_df = venue_dict['qte']
        sts_df = venue_dict['sts']
        
        print(f"    Snapshots iniciales: {len(qte_df):,}")
        
        # Aplicar filtros secuencialmente
        df = qte_df.copy()
        df = self.clean_magic_numbers(df)
        df = self.clean_invalid_prices(df)
        df = self.clean_crossed_book(df)
        df = self.filter_by_market_status(df, sts_df, mic)
        
        print(f"    ‚úì Snapshots finales: {len(df):,} (limpios)")
        
        return df
    
    def clean_all_venues(self, venue_data: Dict[str, Dict]) -> Dict[str, pd.DataFrame]:
        """
        Aplica limpieza a todos los venues de un ISIN.
        
        Args:
            venue_data: Dict {mic: {'qte': df, 'sts': df}}
            
        Returns:
            Dict {mic: cleaned_dataframe}
        """
        print("\n" + "=" * 80)
        print("LIMPIEZA Y VALIDACI√ìN DE DATOS")
        print("=" * 80)
        
        cleaned_data = {}
        
        for mic, data_dict in venue_data.items():
            try:
                cleaned_df = self.clean_venue_data(data_dict, mic)
                
                if len(cleaned_df) > 0:
                    cleaned_data[mic] = cleaned_df
                else:
                    logger.warning(f"  {mic} has 0 snapshots after cleaning")
            
            except Exception as e:
                logger.error(f"  Error cleaning {mic}: {e}")
        
        print(f"\n‚úì Limpieza completada para {len(cleaned_data)} venues")
        
        return cleaned_data
